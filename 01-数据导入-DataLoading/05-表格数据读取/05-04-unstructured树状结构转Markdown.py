from unstructured.partition.pdf import partition_pdf
import os
import json
from datetime import datetime
import re

def is_header_or_footer(text):
    """åˆ¤æ–­æ˜¯å¦ä¸ºé¡µçœ‰é¡µè„šæˆ–é¡µæ•°ä¿¡æ¯"""
    if not text:
        return False
    
    text = text.strip().lower()
    
    # é¡µçœ‰é¡µè„šå¸¸è§æ¨¡å¼
    header_footer_patterns = [
        r'^\d+/\d+$',  # é¡µç æ ¼å¼å¦‚ "1/33"
        r'^\d{1,2}:\d{2}\s+[ap]m$',  # æ—¶é—´æ ¼å¼å¦‚ "7:31 PM"
        r'^\d{1,2}/\d{1,2}/\d{2},\s+\d{1,2}:\d{2}\s+[ap]m$',  # æ—¥æœŸ+æ—¶é—´æ ¼å¼å¦‚ "7/1/23, 11:31 PM"
        r'^\d{1,2}/\d{1,2}/\d{2}$',  # æ—¥æœŸæ ¼å¼å¦‚ "7/1/23"
        r'^the world\'s billionaires - wikipedia$',  # é‡å¤çš„æ ‡é¢˜
        r'^wikipedia$',  # é‡å¤çš„æ ‡é¢˜
        r'^the free encyclopedia$',  # é‡å¤çš„æ ‡é¢˜
        r'^https?://',  # URLé“¾æ¥
        r'^\*https?://',  # å¸¦æ˜Ÿå·çš„URL
        r'^a$',  # å•ä¸ªå­—æ¯
        r'^\*net worth\*$',  # å¸¦æ˜Ÿå·çš„æ ‡é¢˜
        r'^\d{1,2}:\d{2}$',  # çº¯æ—¶é—´æ ¼å¼å¦‚ "11:31"
        r'^page\s+\d+$',  # é¡µç æ ¼å¼å¦‚ "Page 1"
        r'^\d+\s+of\s+\d+$',  # é¡µç æ ¼å¼å¦‚ "1 of 33"
        # æ³¨æ„ï¼šç§»é™¤äº† r'^\d+$' æ¨¡å¼ï¼Œé¿å…è¿‡æ»¤æ‰å¹´ä»½æ ‡é¢˜å¦‚ "2023", "2022" ç­‰
    ]
    
    for pattern in header_footer_patterns:
        if re.match(pattern, text):
            return True
    
    return False

def build_element_tree(elements):
    """æ„å»ºå…ƒç´ çš„æ ‘çŠ¶ç»“æ„"""
    # åˆ›å»ºå…ƒç´ IDåˆ°å…ƒç´ çš„æ˜ å°„
    element_map = {element.id: element for element in elements if hasattr(element, 'id')}
    
    # æ„å»ºæ ‘çŠ¶ç»“æ„
    tree = []
    
    # First pass: create all element_info dicts and link parents
    element_info_map = {}
    for element in elements:
        if not hasattr(element, 'id'):
            continue
        
        element_info = {
            'id': element.id,
            'category': element.category,
            'text': element.text if hasattr(element, 'text') else "",
            'metadata': {
                'page_number': getattr(element.metadata, 'page_number', None),
                'detection_confidence': getattr(element.metadata, 'detection_class_prob', None),
                'parent_id': getattr(element.metadata, 'parent_id', None),
                'coordinates': str(getattr(element.metadata, 'coordinates', None))
            },
            'children': [],
            'parent': None # Will be filled in the second pass
        }
        element_info_map[element.id] = element_info
    
    # Second pass: establish parent-child relationships
    for element_id, element_info in element_info_map.items():
        parent_id = element_info['metadata']['parent_id']
        if parent_id and parent_id in element_info_map:
            parent_element_info = element_info_map[parent_id]
            parent_element_info['children'].append(element_info)
            element_info['parent'] = {
                'id': parent_element_info['id'],
                'category': parent_element_info['category'],
                'text': parent_element_info['text']
            }
        else:
            # Elements without a recognized parent are root elements
            tree.append(element_info)
    
    return tree

def convert_table_to_markdown(table_text):
    """å°†è¡¨æ ¼æ–‡æœ¬è½¬æ¢ä¸ºmarkdownè¡¨æ ¼æ ¼å¼"""
    if not table_text:
        return ""
    
    # æŒ‰è¡Œåˆ†å‰²
    lines = table_text.strip().split('\n')
    if len(lines) < 2:
        return f"```\n{table_text}\n```\n"
    
    # å°è¯•æŒ‰ç©ºæ ¼åˆ†å‰²ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜
    headers = lines[0].split()
    if len(headers) < 2:
        return f"```\n{table_text}\n```\n"
    
    # åˆ›å»ºmarkdownè¡¨æ ¼
    markdown_table = "| " + " | ".join(headers) + " |\n"
    markdown_table += "| " + " | ".join(["---"] * len(headers)) + " |\n"
    
    # å¤„ç†æ•°æ®è¡Œ
    for line in lines[1:]:
        if line.strip():
            cells = line.split()
            if len(cells) >= len(headers):
                markdown_table += "| " + " | ".join(cells[:len(headers)]) + " |\n"
            else:
                # å¦‚æœåˆ—æ•°ä¸åŒ¹é…ï¼Œç”¨ç©ºæ ¼å¡«å……
                padded_cells = cells + [""] * (len(headers) - len(cells))
                markdown_table += "| " + " | ".join(padded_cells) + " |\n"
    
    return markdown_table + "\n"

def convert_tree_to_markdown(tree, level=0):
    """å°†æ ‘çŠ¶ç»“æ„è½¬æ¢ä¸ºmarkdownæ ¼å¼"""
    markdown_content = []
    
    for element in tree:
        # è¿‡æ»¤æ‰é¡µçœ‰é¡µè„šç­‰æ— æ„ä¹‰å†…å®¹
        if is_header_or_footer(element['text']):
            continue
            
        category = element['category']
        text = element['text']
        
        if not text.strip():
            continue
        
        # æ ¹æ®å…ƒç´ ç±»å‹æ·»åŠ ç›¸åº”çš„markdownæ ¼å¼
        if category == "Title":
            markdown_content.append(f"{'#' * (level + 3)} {text}\n\n")
        elif category == "Header":
            markdown_content.append(f"{'#' * (level + 4)} {text}\n\n")
        elif category == "NarrativeText":
            markdown_content.append(f"{text}\n\n")
        elif category == "Table":
            # è¡¨æ ¼ç›´æ¥è½¬æ¢ä¸ºmarkdownè¡¨æ ¼è¯­æ³•
            markdown_content.append("**è¡¨æ ¼å†…å®¹**:\n\n")
            markdown_table = convert_table_to_markdown(text)
            markdown_content.append(markdown_table)
            
            # æ·»åŠ è¡¨æ ¼å…ƒæ•°æ®
            confidence = element['metadata']['detection_confidence']
            if confidence:
                markdown_content.append(f"*è¡¨æ ¼è¯†åˆ«ç½®ä¿¡åº¦: {confidence:.3f}*\n\n")
        elif category == "UncategorizedText":
            markdown_content.append(f"*{text}*\n\n")
        elif category == "Footer":
            # è·³è¿‡é¡µè„š
            continue
        else:
            markdown_content.append(f"{text}\n\n")
        
        # é€’å½’å¤„ç†å­å…ƒç´ 
        if element['children']:
            markdown_content.extend(convert_tree_to_markdown(element['children'], level + 1))
    
    return markdown_content

def convert_to_markdown_unified(elements):
    """ç»Ÿä¸€è½¬æ¢ä¸ºmarkdownæ ¼å¼ï¼Œä¸æŒ‰é¡µåˆ†ç»„"""
    markdown_content = []
    
    # æ·»åŠ æ–‡æ¡£å¤´éƒ¨
    markdown_content.append("# PDFæ–‡æ¡£ç»“æ„æå–æŠ¥å‘Š\n")
    markdown_content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    markdown_content.append(f"**æ€»å…ƒç´ æ•°**: {len(elements)}\n\n")
    markdown_content.append("---\n\n")
    
    # è¿‡æ»¤æ‰é¡µçœ‰é¡µè„š
    filtered_elements = []
    for element in elements:
        text = element.text if hasattr(element, 'text') else ""
        if not is_header_or_footer(text):
            filtered_elements.append(element)
    
    # æ„å»ºæ ‘çŠ¶ç»“æ„
    tree = build_element_tree(filtered_elements)
    
    # è½¬æ¢ä¸ºmarkdown
    markdown_content.extend(convert_tree_to_markdown(tree))
    
    return "".join(markdown_content)

def main():
    # åˆ›å»ºoutputç›®å½•
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)
    print(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    # è§£æ PDF ç»“æ„
    file_path = "/Users/litingguo/project_station/ai/rag-in-action/90-æ–‡æ¡£-Data/å¤æ‚PDF/billionaires_page-1-5.pdf"
    
    if not os.path.exists(file_path):
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    try:
        print("æ­£åœ¨è§£æPDFæ–‡ä»¶...")
        print("ä½¿ç”¨é«˜ç²¾åº¦ç­–ç•¥ (strategy='hi_res')...")
        
        # ä½¿ç”¨é«˜ç²¾åº¦ç­–ç•¥è§£æPDF
        elements = partition_pdf(
            file_path,
            strategy="hi_res",
        )
        
        print(f"æˆåŠŸè§£æPDFï¼Œå…±æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
        
        # ç»Ÿè®¡å„ç±»å‹å…ƒç´ æ•°é‡
        category_counts = {}
        for element in elements:
            category = element.category
            category_counts[category] = category_counts.get(category, 0) + 1
        
        print("\nå…ƒç´ ç±»å‹ç»Ÿè®¡:")
        for category, count in category_counts.items():
            print(f"  {category}: {count}")
        
        # æ„å»ºæ ‘çŠ¶ç»“æ„
        print("\næ­£åœ¨æ„å»ºå…ƒç´ æ ‘çŠ¶ç»“æ„...")
        tree = build_element_tree(elements)
        print(f"æ„å»ºäº† {len(tree)} ä¸ªæ ¹çº§å…ƒç´ ")
        
        # è½¬æ¢ä¸ºmarkdownï¼ˆä¸æŒ‰é¡µåˆ†ç»„ï¼‰
        print("æ­£åœ¨è½¬æ¢ä¸ºMarkdownæ ¼å¼...")
        markdown_content = convert_to_markdown_unified(elements)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜æ–‡ä»¶
        markdown_file = os.path.join(output_dir, f"document_structure_unified_{timestamp}.md")
        json_file = os.path.join(output_dir, f"document_structure_unified_{timestamp}.json")
        
        print(f"\næ­£åœ¨ä¿å­˜æ–‡ä»¶...")
        
        # ä¿å­˜markdownæ–‡ä»¶
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        print(f"âœ… Markdownæ–‡ä»¶å·²ä¿å­˜åˆ°: {markdown_file}")
        
        # ä¿å­˜æ ‘çŠ¶ç»“æ„JSONæ–‡ä»¶
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(tree, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ ‘çŠ¶ç»“æ„æ•°æ®å·²ä¿å­˜åˆ°: {json_file}")
        
        print(f"\nğŸ‰ æ–‡æ¡£ç»“æ„æå–å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°ä¿¡æ¯
        for file_path in [markdown_file, json_file]:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                print(f"ğŸ“„ {os.path.basename(file_path)}: {size} bytes")
        
        # æ˜¾ç¤ºmarkdowné¢„è§ˆ
        print(f"\nğŸ“ Markdownæ–‡ä»¶é¢„è§ˆ (å‰500å­—ç¬¦):")
        print("-" * 50)
        print(markdown_content[:500] + "..." if len(markdown_content) > 500 else markdown_content)
        print("-" * 50)
        
    except Exception as e:
        print(f"å¤„ç†PDFæ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
